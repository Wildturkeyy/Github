{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13700\\1908094005.py:1: The name tf.enable_eager_execution is deprecated. Please use tf.compat.v1.enable_eager_execution instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': 'breast_cancer.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datasets.load_breast_cancer()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30) float64 (569,) int32\n"
     ]
    }
   ],
   "source": [
    "X = data.data\n",
    "y = data.target\n",
    "print(X.shape, X.dtype, y.shape, y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30) float32 (569,) float32\n"
     ]
    }
   ],
   "source": [
    "# 타입 및 형태 변환.\n",
    "X = np.array(X, dtype='float32')\n",
    "y = np.array(y, dtype='float32')\n",
    "print(X.shape, X.dtype, y.shape, y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.reshape(-1,1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X,y 8:2로 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.390e+01, 1.924e+01, 8.873e+01, ..., 8.150e-02, 2.356e-01,\n",
       "        7.603e-02],\n",
       "       [8.571e+00, 1.310e+01, 5.453e+01, ..., 8.512e-02, 2.983e-01,\n",
       "        1.049e-01],\n",
       "       [1.020e+01, 1.748e+01, 6.505e+01, ..., 3.571e-02, 2.868e-01,\n",
       "        7.809e-02],\n",
       "       ...,\n",
       "       [1.327e+01, 1.476e+01, 8.474e+01, ..., 1.001e-01, 2.027e-01,\n",
       "        6.206e-02],\n",
       "       [2.351e+01, 2.427e+01, 1.551e+02, ..., 2.089e-01, 2.593e-01,\n",
       "        7.738e-02],\n",
       "       [2.094e+01, 2.356e+01, 1.389e+02, ..., 2.105e-01, 3.126e-01,\n",
       "        7.849e-02]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (114, 30) (455, 1) (114, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.390e+01, 1.924e+01, 8.873e+01, ..., 8.150e-02, 2.356e-01,\n",
       "        7.603e-02],\n",
       "       [8.571e+00, 1.310e+01, 5.453e+01, ..., 8.512e-02, 2.983e-01,\n",
       "        1.049e-01],\n",
       "       [1.020e+01, 1.748e+01, 6.505e+01, ..., 3.571e-02, 2.868e-01,\n",
       "        7.809e-02],\n",
       "       ...,\n",
       "       [1.327e+01, 1.476e+01, 8.474e+01, ..., 1.001e-01, 2.027e-01,\n",
       "        6.206e-02],\n",
       "       [2.351e+01, 2.427e+01, 1.551e+02, ..., 2.089e-01, 2.593e-01,\n",
       "        7.738e-02],\n",
       "       [2.094e+01, 2.356e+01, 1.389e+02, ..., 2.105e-01, 3.126e-01,\n",
       "        7.849e-02]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습하기 전에 데이터 표준화\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "train_scaled = ss.transform(X_train)\n",
    "test_scaled = ss.transform(X_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid 함수 정의\n",
    "\n",
    "def sigmoid(h):\n",
    "    return 1 / (1 + np.exp(-h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# w, b 초기화 시키는 객체 생성\n",
    "initializer = tf.contrib.layers.xavier_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w 및 b 생성\n",
    "w = tf.Variable(initializer([30,1]))\n",
    "b = tf.Variable(initializer([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=32, shape=(455, 1), dtype=float32, numpy=\n",
       "array([[3.47834796e-01],\n",
       "       [5.34180760e-01],\n",
       "       [9.61123407e-02],\n",
       "       [5.12585938e-01],\n",
       "       [2.71951377e-01],\n",
       "       [4.22209620e-01],\n",
       "       [5.91860533e-01],\n",
       "       [4.20177877e-01],\n",
       "       [1.98770255e-01],\n",
       "       [1.05847985e-01],\n",
       "       [1.80189967e-01],\n",
       "       [2.77128518e-01],\n",
       "       [1.47601217e-01],\n",
       "       [3.85194361e-01],\n",
       "       [6.56479001e-02],\n",
       "       [5.06255627e-02],\n",
       "       [4.28464830e-01],\n",
       "       [1.78143352e-01],\n",
       "       [5.46301126e-01],\n",
       "       [9.03527737e-02],\n",
       "       [3.85602891e-01],\n",
       "       [3.88250351e-02],\n",
       "       [1.89672709e-01],\n",
       "       [4.83201236e-01],\n",
       "       [4.96160507e-01],\n",
       "       [3.80847752e-01],\n",
       "       [2.02939361e-01],\n",
       "       [4.52888042e-01],\n",
       "       [2.56575942e-01],\n",
       "       [3.92066419e-01],\n",
       "       [2.90699840e-01],\n",
       "       [5.17323613e-01],\n",
       "       [3.24406505e-01],\n",
       "       [6.51985109e-02],\n",
       "       [1.15690708e-01],\n",
       "       [3.70377988e-01],\n",
       "       [2.56170273e-01],\n",
       "       [2.44947076e-02],\n",
       "       [6.60435259e-02],\n",
       "       [4.90700901e-01],\n",
       "       [1.51844412e-01],\n",
       "       [4.16037440e-03],\n",
       "       [5.17253876e-02],\n",
       "       [1.84122950e-01],\n",
       "       [4.36528385e-01],\n",
       "       [3.62503529e-02],\n",
       "       [5.05200624e-02],\n",
       "       [2.44709849e-02],\n",
       "       [1.32442415e-01],\n",
       "       [1.72553599e-01],\n",
       "       [1.33317411e-02],\n",
       "       [2.50274420e-01],\n",
       "       [1.51254237e-02],\n",
       "       [4.63383555e-01],\n",
       "       [8.92341137e-04],\n",
       "       [2.32483834e-01],\n",
       "       [3.61821055e-03],\n",
       "       [4.58660245e-01],\n",
       "       [2.95624733e-01],\n",
       "       [1.55303359e-01],\n",
       "       [3.06054354e-02],\n",
       "       [3.05404782e-01],\n",
       "       [1.89585507e-01],\n",
       "       [8.76651108e-02],\n",
       "       [1.63758159e-01],\n",
       "       [6.64550066e-02],\n",
       "       [5.79686761e-01],\n",
       "       [6.01928532e-02],\n",
       "       [9.41396952e-02],\n",
       "       [3.39091420e-01],\n",
       "       [2.43549645e-01],\n",
       "       [4.09403145e-01],\n",
       "       [2.95066476e-01],\n",
       "       [2.72709578e-01],\n",
       "       [2.99906343e-01],\n",
       "       [6.78830743e-02],\n",
       "       [5.07838428e-02],\n",
       "       [2.58342922e-02],\n",
       "       [5.72478175e-01],\n",
       "       [3.05067241e-01],\n",
       "       [6.44435525e-01],\n",
       "       [1.50357813e-01],\n",
       "       [1.00384355e-02],\n",
       "       [2.07808375e-01],\n",
       "       [3.01254094e-01],\n",
       "       [2.24151522e-01],\n",
       "       [3.35643679e-01],\n",
       "       [9.19977129e-02],\n",
       "       [3.88970077e-01],\n",
       "       [1.92347914e-01],\n",
       "       [1.97540760e-01],\n",
       "       [2.01784998e-01],\n",
       "       [2.75343716e-01],\n",
       "       [5.89977086e-01],\n",
       "       [7.68514216e-01],\n",
       "       [1.21222436e-02],\n",
       "       [6.17779076e-01],\n",
       "       [1.35690331e-01],\n",
       "       [2.79836416e-01],\n",
       "       [4.70268726e-02],\n",
       "       [1.40733182e-01],\n",
       "       [1.76333934e-01],\n",
       "       [5.18092513e-03],\n",
       "       [1.84864014e-01],\n",
       "       [3.83366853e-01],\n",
       "       [9.14624929e-02],\n",
       "       [8.96883905e-02],\n",
       "       [8.27226937e-02],\n",
       "       [2.94715166e-04],\n",
       "       [2.33133882e-01],\n",
       "       [5.81976175e-02],\n",
       "       [4.69639897e-03],\n",
       "       [1.70433223e-02],\n",
       "       [2.96537697e-01],\n",
       "       [6.86481595e-02],\n",
       "       [2.10206211e-02],\n",
       "       [1.23914659e-01],\n",
       "       [4.14049864e-01],\n",
       "       [1.97668463e-01],\n",
       "       [2.28312165e-01],\n",
       "       [5.07724285e-02],\n",
       "       [6.02686167e-01],\n",
       "       [4.57414329e-01],\n",
       "       [3.83024186e-01],\n",
       "       [2.57192731e-01],\n",
       "       [1.44781083e-01],\n",
       "       [5.44012189e-02],\n",
       "       [2.14159787e-01],\n",
       "       [2.30931967e-01],\n",
       "       [2.97574997e-02],\n",
       "       [4.88337427e-01],\n",
       "       [2.70950258e-01],\n",
       "       [1.19283199e-02],\n",
       "       [2.69772947e-01],\n",
       "       [1.40423089e-01],\n",
       "       [5.39336801e-02],\n",
       "       [3.41758370e-01],\n",
       "       [1.40254110e-01],\n",
       "       [6.50054514e-02],\n",
       "       [2.47927755e-01],\n",
       "       [2.54891813e-02],\n",
       "       [1.45223856e-01],\n",
       "       [3.64813805e-02],\n",
       "       [1.42283648e-01],\n",
       "       [6.14514232e-01],\n",
       "       [7.63979554e-03],\n",
       "       [6.68412745e-01],\n",
       "       [3.29643488e-02],\n",
       "       [3.04203272e-01],\n",
       "       [2.92734504e-01],\n",
       "       [2.34358490e-01],\n",
       "       [1.08259708e-01],\n",
       "       [1.72636211e-02],\n",
       "       [3.79585624e-02],\n",
       "       [6.58435524e-02],\n",
       "       [6.00419700e-01],\n",
       "       [1.49159759e-01],\n",
       "       [1.86335444e-02],\n",
       "       [2.02662736e-01],\n",
       "       [3.65800381e-01],\n",
       "       [3.47683609e-01],\n",
       "       [3.57089758e-01],\n",
       "       [1.00019336e-01],\n",
       "       [2.60104865e-01],\n",
       "       [4.34587598e-02],\n",
       "       [4.22780514e-01],\n",
       "       [1.52925998e-01],\n",
       "       [2.45159864e-01],\n",
       "       [3.56949985e-01],\n",
       "       [2.66157269e-01],\n",
       "       [3.73449415e-01],\n",
       "       [4.83139455e-02],\n",
       "       [5.10197878e-01],\n",
       "       [2.48875201e-01],\n",
       "       [2.96395957e-01],\n",
       "       [1.03140712e-01],\n",
       "       [1.12534940e-01],\n",
       "       [2.00108290e-01],\n",
       "       [1.51422173e-01],\n",
       "       [1.65977091e-01],\n",
       "       [2.66193807e-01],\n",
       "       [2.43059039e-01],\n",
       "       [6.11703992e-02],\n",
       "       [3.05745006e-01],\n",
       "       [2.07443476e-01],\n",
       "       [1.94283873e-01],\n",
       "       [2.70056069e-01],\n",
       "       [4.54835474e-01],\n",
       "       [3.57486606e-02],\n",
       "       [1.40193403e-01],\n",
       "       [2.37309575e-01],\n",
       "       [2.52742290e-01],\n",
       "       [2.20205545e-01],\n",
       "       [5.17701805e-02],\n",
       "       [2.68376708e-01],\n",
       "       [5.70278227e-01],\n",
       "       [3.77680182e-01],\n",
       "       [2.33362406e-01],\n",
       "       [6.75509274e-02],\n",
       "       [3.91770035e-01],\n",
       "       [2.68177688e-02],\n",
       "       [4.71714735e-02],\n",
       "       [4.74262625e-01],\n",
       "       [1.16355270e-01],\n",
       "       [4.79549170e-04],\n",
       "       [4.96731699e-02],\n",
       "       [4.69141871e-01],\n",
       "       [6.07173145e-02],\n",
       "       [1.86459124e-02],\n",
       "       [2.79188156e-04],\n",
       "       [4.41551417e-01],\n",
       "       [1.64318085e-03],\n",
       "       [2.97365785e-02],\n",
       "       [3.38403285e-02],\n",
       "       [1.17897183e-01],\n",
       "       [8.54723155e-02],\n",
       "       [4.24215525e-01],\n",
       "       [2.62053013e-02],\n",
       "       [4.20224100e-01],\n",
       "       [3.47274631e-01],\n",
       "       [1.83606416e-01],\n",
       "       [1.89477116e-01],\n",
       "       [3.87244821e-01],\n",
       "       [1.34040415e-01],\n",
       "       [6.35894597e-01],\n",
       "       [2.09976226e-01],\n",
       "       [1.47929728e-01],\n",
       "       [5.89850783e-01],\n",
       "       [1.53646380e-01],\n",
       "       [6.58338666e-02],\n",
       "       [1.42468840e-01],\n",
       "       [4.25984591e-01],\n",
       "       [5.10099828e-02],\n",
       "       [2.80546367e-01],\n",
       "       [1.65447861e-01],\n",
       "       [3.28324139e-02],\n",
       "       [3.56173933e-01],\n",
       "       [8.25948715e-02],\n",
       "       [1.31201804e-01],\n",
       "       [2.83588111e-01],\n",
       "       [4.84648794e-01],\n",
       "       [1.64036453e-02],\n",
       "       [1.21482611e-02],\n",
       "       [5.76472700e-01],\n",
       "       [3.72227550e-01],\n",
       "       [1.77448928e-01],\n",
       "       [5.00012934e-02],\n",
       "       [1.31009102e-01],\n",
       "       [9.40278471e-02],\n",
       "       [2.62566209e-02],\n",
       "       [1.18905902e-01],\n",
       "       [3.84055912e-01],\n",
       "       [2.00937241e-01],\n",
       "       [7.07807541e-02],\n",
       "       [3.81312579e-01],\n",
       "       [1.76525176e-01],\n",
       "       [5.78980505e-01],\n",
       "       [2.25990415e-01],\n",
       "       [3.31825554e-01],\n",
       "       [2.21585840e-01],\n",
       "       [5.79437077e-01],\n",
       "       [2.16747820e-02],\n",
       "       [2.55329132e-01],\n",
       "       [1.35883719e-01],\n",
       "       [2.68391252e-01],\n",
       "       [6.29957438e-01],\n",
       "       [1.99060798e-01],\n",
       "       [9.76257622e-02],\n",
       "       [3.36733520e-01],\n",
       "       [2.38708079e-01],\n",
       "       [2.93632448e-02],\n",
       "       [2.04206407e-02],\n",
       "       [6.64082050e-01],\n",
       "       [2.59078860e-01],\n",
       "       [2.72836596e-01],\n",
       "       [8.08304250e-02],\n",
       "       [4.11323547e-01],\n",
       "       [6.39307499e-03],\n",
       "       [4.60788310e-02],\n",
       "       [1.15405381e-01],\n",
       "       [1.63607895e-01],\n",
       "       [4.96417344e-01],\n",
       "       [2.93332309e-01],\n",
       "       [3.18686128e-01],\n",
       "       [2.48207003e-01],\n",
       "       [5.80941916e-01],\n",
       "       [1.98712945e-02],\n",
       "       [1.74620152e-02],\n",
       "       [4.15533781e-02],\n",
       "       [5.78319728e-02],\n",
       "       [2.64589846e-01],\n",
       "       [5.24600446e-01],\n",
       "       [2.51147211e-01],\n",
       "       [3.72882605e-01],\n",
       "       [1.35985225e-01],\n",
       "       [5.59898555e-01],\n",
       "       [6.88790739e-01],\n",
       "       [5.35769701e-01],\n",
       "       [4.92131025e-01],\n",
       "       [2.76159197e-01],\n",
       "       [2.18166173e-01],\n",
       "       [3.51562440e-01],\n",
       "       [2.75355577e-01],\n",
       "       [6.68069720e-03],\n",
       "       [3.49301398e-02],\n",
       "       [4.31490421e-01],\n",
       "       [1.19696140e-01],\n",
       "       [1.91067696e-01],\n",
       "       [4.36158478e-02],\n",
       "       [3.06220949e-02],\n",
       "       [4.83178228e-01],\n",
       "       [1.49198860e-01],\n",
       "       [4.64299500e-01],\n",
       "       [3.56401205e-01],\n",
       "       [2.63540328e-01],\n",
       "       [2.61223525e-01],\n",
       "       [1.68966532e-01],\n",
       "       [3.12336385e-02],\n",
       "       [2.78825670e-01],\n",
       "       [4.73828346e-01],\n",
       "       [9.72061455e-02],\n",
       "       [3.53950739e-01],\n",
       "       [1.02288663e-01],\n",
       "       [2.66365528e-01],\n",
       "       [1.58878684e-01],\n",
       "       [2.02484012e-01],\n",
       "       [1.79777354e-01],\n",
       "       [6.13872707e-02],\n",
       "       [2.20689923e-01],\n",
       "       [5.35615802e-01],\n",
       "       [8.56313109e-03],\n",
       "       [9.67579186e-02],\n",
       "       [6.39229119e-02],\n",
       "       [5.15084624e-01],\n",
       "       [4.81729031e-01],\n",
       "       [4.28706229e-01],\n",
       "       [9.30789113e-03],\n",
       "       [1.12962723e-03],\n",
       "       [2.61160314e-01],\n",
       "       [3.80782485e-01],\n",
       "       [5.22399545e-01],\n",
       "       [1.00825161e-01],\n",
       "       [2.53355891e-01],\n",
       "       [2.59652734e-02],\n",
       "       [1.60528928e-01],\n",
       "       [4.47176337e-01],\n",
       "       [1.71414822e-01],\n",
       "       [5.98955154e-03],\n",
       "       [5.65600038e-01],\n",
       "       [1.19605958e-02],\n",
       "       [1.49867982e-01],\n",
       "       [1.04945719e-01],\n",
       "       [5.67709506e-02],\n",
       "       [2.97148645e-01],\n",
       "       [1.53172165e-01],\n",
       "       [8.92876387e-02],\n",
       "       [5.26132286e-02],\n",
       "       [6.44605756e-02],\n",
       "       [9.48454440e-02],\n",
       "       [8.74266028e-02],\n",
       "       [1.30268306e-01],\n",
       "       [1.14947557e-04],\n",
       "       [2.98025310e-02],\n",
       "       [4.65021431e-02],\n",
       "       [7.98358619e-02],\n",
       "       [2.49403864e-01],\n",
       "       [2.24921107e-02],\n",
       "       [2.20826268e-02],\n",
       "       [6.79462254e-02],\n",
       "       [3.80539715e-01],\n",
       "       [1.89545006e-01],\n",
       "       [3.51482302e-01],\n",
       "       [1.63693190e-01],\n",
       "       [6.83747828e-02],\n",
       "       [4.76129800e-01],\n",
       "       [1.62259936e-01],\n",
       "       [3.81320447e-01],\n",
       "       [1.23994499e-01],\n",
       "       [3.35521340e-01],\n",
       "       [4.83820826e-01],\n",
       "       [5.65597713e-01],\n",
       "       [2.47266501e-01],\n",
       "       [6.11310303e-02],\n",
       "       [8.62983167e-02],\n",
       "       [3.19599390e-01],\n",
       "       [3.90134156e-02],\n",
       "       [1.13072515e-01],\n",
       "       [6.00352287e-02],\n",
       "       [2.82080173e-02],\n",
       "       [1.57998383e-01],\n",
       "       [5.07735074e-01],\n",
       "       [3.48739654e-01],\n",
       "       [8.94223452e-02],\n",
       "       [3.27285647e-01],\n",
       "       [2.22142518e-01],\n",
       "       [2.67250180e-01],\n",
       "       [1.37965471e-01],\n",
       "       [2.87444592e-02],\n",
       "       [3.97557020e-02],\n",
       "       [5.45401573e-01],\n",
       "       [2.65309513e-01],\n",
       "       [6.57519102e-02],\n",
       "       [4.22250986e-01],\n",
       "       [3.60191464e-01],\n",
       "       [2.12561220e-01],\n",
       "       [1.77319050e-02],\n",
       "       [1.88041568e-01],\n",
       "       [2.55882382e-01],\n",
       "       [6.28448248e-01],\n",
       "       [3.41265798e-02],\n",
       "       [8.14697444e-02],\n",
       "       [6.14734292e-01],\n",
       "       [1.66887969e-01],\n",
       "       [2.61964411e-01],\n",
       "       [6.44746423e-02],\n",
       "       [4.60880101e-02],\n",
       "       [7.71687329e-02],\n",
       "       [1.32163763e-01],\n",
       "       [1.98417157e-01],\n",
       "       [5.34719765e-01],\n",
       "       [1.52738035e-01],\n",
       "       [2.55124658e-01],\n",
       "       [1.74927741e-01],\n",
       "       [2.16604739e-01],\n",
       "       [5.64596713e-01],\n",
       "       [2.43320763e-02],\n",
       "       [4.03189152e-01],\n",
       "       [1.44807488e-01],\n",
       "       [4.08816159e-01],\n",
       "       [5.61213553e-01],\n",
       "       [3.81047577e-01],\n",
       "       [7.73850083e-02],\n",
       "       [1.32194191e-01],\n",
       "       [1.55665278e-02],\n",
       "       [1.23929739e-01],\n",
       "       [1.38040930e-01],\n",
       "       [1.81755722e-01],\n",
       "       [4.82715607e-01],\n",
       "       [5.76146483e-01],\n",
       "       [1.78759933e-01],\n",
       "       [3.29628170e-01],\n",
       "       [4.93215024e-02],\n",
       "       [5.12253642e-02],\n",
       "       [2.14571357e-01],\n",
       "       [2.23321438e-01],\n",
       "       [1.85079366e-01],\n",
       "       [3.09336782e-02],\n",
       "       [3.92545283e-01],\n",
       "       [7.27134943e-03],\n",
       "       [3.83233458e-01],\n",
       "       [2.31972247e-01],\n",
       "       [1.14811361e-02],\n",
       "       [4.90989000e-01],\n",
       "       [3.91110629e-02],\n",
       "       [1.71940085e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측값 계산하기\n",
    "hypothesis = tf.sigmoid(tf.matmul(train_scaled, w) + b)\n",
    "hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13700\\3535778523.py:2: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# optimizer 생성\n",
    "optimizer = tf.train.AdamOptimizer(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13700\\4277676140.py:6: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "--------------------------------------------------\n",
      "step : 0, cost : 0.8933848142623901, w : [[-0.34868118]\n",
      " [-0.10224021]\n",
      " [ 0.31647217]\n",
      " [ 0.1416692 ]\n",
      " [ 0.10038077]\n",
      " [-0.23194355]\n",
      " [ 0.08240257]\n",
      " [ 0.02763994]\n",
      " [-0.23255244]\n",
      " [-0.20825353]\n",
      " [-0.32424504]\n",
      " [-0.21174878]\n",
      " [-0.11801939]\n",
      " [ 0.19991283]\n",
      " [ 0.23751384]\n",
      " [-0.41845748]\n",
      " [-0.32547498]\n",
      " [ 0.0846998 ]\n",
      " [-0.2835544 ]\n",
      " [ 0.40646505]\n",
      " [ 0.04735227]\n",
      " [-0.30897993]\n",
      " [-0.37632427]\n",
      " [-0.3677434 ]\n",
      " [-0.0842912 ]\n",
      " [-0.22490259]\n",
      " [-0.03016136]\n",
      " [ 0.331087  ]\n",
      " [ 0.00467457]\n",
      " [-0.11024282]], b : [-1.7199556]\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "step : 10, cost : 0.8433213233947754, w : [[-0.35865855]\n",
      " [-0.11219844]\n",
      " [ 0.30649516]\n",
      " [ 0.1316912 ]\n",
      " [ 0.09041109]\n",
      " [-0.24190935]\n",
      " [ 0.07243036]\n",
      " [ 0.01766457]\n",
      " [-0.2425063 ]\n",
      " [-0.19824988]\n",
      " [-0.3342206 ]\n",
      " [-0.20174797]\n",
      " [-0.12799354]\n",
      " [ 0.18993513]\n",
      " [ 0.24748263]\n",
      " [-0.42837065]\n",
      " [-0.33539107]\n",
      " [ 0.07474368]\n",
      " [-0.2735626 ]\n",
      " [ 0.41653645]\n",
      " [ 0.0373746 ]\n",
      " [-0.31894356]\n",
      " [-0.38630137]\n",
      " [-0.37772176]\n",
      " [-0.09426834]\n",
      " [-0.23486973]\n",
      " [-0.04013098]\n",
      " [ 0.3211135 ]\n",
      " [-0.00529779]\n",
      " [-0.12020174]], b : [-1.7099694]\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "step : 20, cost : 0.7966592311859131, w : [[-0.36853415]\n",
      " [-0.12196942]\n",
      " [ 0.2966217 ]\n",
      " [ 0.12181168]\n",
      " [ 0.08057855]\n",
      " [-0.25171933]\n",
      " [ 0.0625835 ]\n",
      " [ 0.0077998 ]\n",
      " [-0.2522482 ]\n",
      " [-0.18823193]\n",
      " [-0.34408784]\n",
      " [-0.19175236]\n",
      " [-0.13785264]\n",
      " [ 0.18005629]\n",
      " [ 0.2573032 ]\n",
      " [-0.43786126]\n",
      " [-0.34489843]\n",
      " [ 0.06499078]\n",
      " [-0.26361156]\n",
      " [ 0.42688936]\n",
      " [ 0.02749699]\n",
      " [-0.32874486]\n",
      " [-0.3961755 ]\n",
      " [-0.38760343]\n",
      " [-0.10414273]\n",
      " [-0.24468699]\n",
      " [-0.0499625 ]\n",
      " [ 0.31125972]\n",
      " [-0.01514485]\n",
      " [-0.12997115]], b : [-1.7000471]\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "step : 30, cost : 0.7536138296127319, w : [[-0.3782356 ]\n",
      " [-0.1314238 ]\n",
      " [ 0.28692558]\n",
      " [ 0.11209989]\n",
      " [ 0.07098196]\n",
      " [-0.26125845]\n",
      " [ 0.05295185]\n",
      " [-0.00187588]\n",
      " [-0.26161793]\n",
      " [-0.1781976 ]\n",
      " [-0.35377342]\n",
      " [-0.18179022]\n",
      " [-0.14751744]\n",
      " [ 0.17034382]\n",
      " [ 0.26684776]\n",
      " [-0.44654894]\n",
      " [-0.3536262 ]\n",
      " [ 0.05559859]\n",
      " [-0.2537428 ]\n",
      " [ 0.43763804]\n",
      " [ 0.01779009]\n",
      " [-0.33827266]\n",
      " [-0.40587372]\n",
      " [-0.39732122]\n",
      " [-0.11384134]\n",
      " [-0.2542429 ]\n",
      " [-0.05955436]\n",
      " [ 0.3016123 ]\n",
      " [-0.02477531]\n",
      " [-0.13940641]], b : [-1.6902373]\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "step : 40, cost : 0.7141802310943604, w : [[-0.3877142 ]\n",
      " [-0.14048325]\n",
      " [ 0.27745637]\n",
      " [ 0.10260145]\n",
      " [ 0.06168696]\n",
      " [-0.270447  ]\n",
      " [ 0.04359554]\n",
      " [-0.01131059]\n",
      " [-0.27050155]\n",
      " [-0.16815752]\n",
      " [-0.36323223]\n",
      " [-0.17190936]\n",
      " [-0.15693834]\n",
      " [ 0.16083989]\n",
      " [ 0.2760026 ]\n",
      " [-0.45409164]\n",
      " [-0.3612346 ]\n",
      " [ 0.04668349]\n",
      " [-0.24400035]\n",
      " [ 0.4487851 ]\n",
      " [ 0.00830077]\n",
      " [-0.3474601 ]\n",
      " [-0.41534755]\n",
      " [-0.40683126]\n",
      " [-0.12331601]\n",
      " [-0.2634593 ]\n",
      " [-0.06883621]\n",
      " [ 0.29223025]\n",
      " [-0.03412646]\n",
      " [-0.14840332]], b : [-1.6805749]\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "step : 50, cost : 0.6781874895095825, w : [[-0.39694348]\n",
      " [-0.14911729]\n",
      " [ 0.26824078]\n",
      " [ 0.09334036]\n",
      " [ 0.05272691]\n",
      " [-0.27924034]\n",
      " [ 0.03454608]\n",
      " [-0.02047745]\n",
      " [-0.27883282]\n",
      " [-0.15813251]\n",
      " [-0.37244466]\n",
      " [-0.1621683 ]\n",
      " [-0.16609263]\n",
      " [ 0.15156415]\n",
      " [ 0.28467143]\n",
      " [-0.46021152]\n",
      " [-0.36743742]\n",
      " [ 0.03831714]\n",
      " [-0.23442751]\n",
      " [ 0.4602653 ]\n",
      " [-0.00094611]\n",
      " [-0.35628092]\n",
      " [-0.42457128]\n",
      " [-0.41611117]\n",
      " [-0.13254201]\n",
      " [-0.27229136]\n",
      " [-0.07776856]\n",
      " [ 0.28314593]\n",
      " [-0.04316341]\n",
      " [-0.15690072]], b : [-1.6710808]\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "step : 60, cost : 0.6453665494918823, w : [[-0.4059132 ]\n",
      " [-0.15732937]\n",
      " [ 0.2592892 ]\n",
      " [ 0.08432514]\n",
      " [ 0.04411108]\n",
      " [-0.28762102]\n",
      " [ 0.02581381]\n",
      " [-0.02936775]\n",
      " [-0.28658354]\n",
      " [-0.14814933]\n",
      " [-0.38140866]\n",
      " [-0.15262654]\n",
      " [-0.1749765 ]\n",
      " [ 0.14252059]\n",
      " [ 0.29277283]\n",
      " [-0.46470258]\n",
      " [-0.37200886]\n",
      " [ 0.03053414]\n",
      " [-0.22506443]\n",
      " [ 0.47198594]\n",
      " [-0.00994149]\n",
      " [-0.36473766]\n",
      " [-0.4335354 ]\n",
      " [-0.4251536 ]\n",
      " [-0.14151174]\n",
      " [-0.2807202 ]\n",
      " [-0.08633555]\n",
      " [ 0.27437168]\n",
      " [-0.05187189]\n",
      " [-0.1648722 ]], b : [-1.661764]\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "step : 70, cost : 0.6154069900512695, w : [[-0.4146233 ]\n",
      " [-0.16514237]\n",
      " [ 0.25060156]\n",
      " [ 0.07555477]\n",
      " [ 0.0358334 ]\n",
      " [-0.29558957]\n",
      " [ 0.01739546]\n",
      " [-0.03798424]\n",
      " [-0.2937517 ]\n",
      " [-0.13823652]\n",
      " [-0.3901323 ]\n",
      " [-0.14333738]\n",
      " [-0.18359736]\n",
      " [ 0.13370396]\n",
      " [ 0.30023557]\n",
      " [-0.46743459]\n",
      " [-0.37478927]\n",
      " [ 0.02334186]\n",
      " [-0.21594614]\n",
      " [ 0.48385143]\n",
      " [-0.01868612]\n",
      " [-0.37284875]\n",
      " [-0.4422407 ]\n",
      " [-0.4339605 ]\n",
      " [-0.15022823]\n",
      " [-0.28874427]\n",
      " [-0.09453692]\n",
      " [ 0.265907  ]\n",
      " [-0.06025105]\n",
      " [-0.17231618]], b : [-1.6526248]\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "step : 80, cost : 0.5879949331283569, w : [[-0.4230795 ]\n",
      " [-0.17258832]\n",
      " [ 0.24217157]\n",
      " [ 0.06702277]\n",
      " [ 0.02787898]\n",
      " [-0.30315772]\n",
      " [ 0.0092797 ]\n",
      " [-0.04633618]\n",
      " [-0.30035225]\n",
      " [-0.12842186]\n",
      " [-0.39862868]\n",
      " [-0.1343435 ]\n",
      " [-0.19196849]\n",
      " [ 0.1251042 ]\n",
      " [ 0.30699426]\n",
      " [-0.46835774]\n",
      " [-0.37569433]\n",
      " [ 0.01672851]\n",
      " [-0.20710137]\n",
      " [ 0.49577457]\n",
      " [-0.02718627]\n",
      " [-0.38064012]\n",
      " [-0.4506938 ]\n",
      " [-0.4425388 ]\n",
      " [-0.15870082]\n",
      " [-0.29637304]\n",
      " [-0.10238218]\n",
      " [ 0.2577435 ]\n",
      " [-0.0683081 ]\n",
      " [-0.17924798]], b : [-1.6436598]\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "step : 90, cost : 0.5628335475921631, w : [[-0.43129075]\n",
      " [-0.17970207]\n",
      " [ 0.23398994]\n",
      " [ 0.05871989]\n",
      " [ 0.02022853]\n",
      " [-0.310344  ]\n",
      " [ 0.00145072]\n",
      " [-0.05443629]\n",
      " [-0.30641088]\n",
      " [-0.11873058]\n",
      " [-0.40691286]\n",
      " [-0.12567537]\n",
      " [-0.20010567]\n",
      " [ 0.11670913]\n",
      " [ 0.31298694]\n",
      " [-0.46750543]\n",
      " [-0.3747236 ]\n",
      " [ 0.01066895]\n",
      " [-0.19855215]\n",
      " [ 0.5076801 ]\n",
      " [-0.03545117]\n",
      " [-0.38813996]\n",
      " [-0.4589044 ]\n",
      " [-0.45089808]\n",
      " [-0.16694224]\n",
      " [-0.30362266]\n",
      " [-0.10988665]\n",
      " [ 0.24986872]\n",
      " [-0.07605501]\n",
      " [-0.18569426]], b : [-1.6348622]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 반복해서 w와 b를 찾음\n",
    "\n",
    "for step in range(100):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = tf.sigmoid(tf.matmul(train_scaled, w) + b)\n",
    "        cost = -tf.reduce_mean(y_train * tf.log(hypothesis) + (1 - y_train) * tf.log(1 - hypothesis))\n",
    "        grads = tape.gradient(cost, [w,b])\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, [w,b]))\n",
    "\n",
    "    if step % 10 ==0:\n",
    "        print('-'*50)\n",
    "        print(f'step : {step}, cost : {cost.numpy()}, w : {w.numpy()}, b : {b.numpy()}')\n",
    "        print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(30, 1) dtype=float32, numpy=\n",
      "array([[-0.43848008],\n",
      "       [-0.18584868],\n",
      "       [ 0.22682972],\n",
      "       [ 0.05143448],\n",
      "       [ 0.01358586],\n",
      "       [-0.31650332],\n",
      "       [-0.00536504],\n",
      "       [-0.06152282],\n",
      "       [-0.31142667],\n",
      "       [-0.11013213],\n",
      "       [-0.41419986],\n",
      "       [-0.11816803],\n",
      "       [-0.20724265],\n",
      "       [ 0.109318  ],\n",
      "       [ 0.31767634],\n",
      "       [-0.46531036],\n",
      "       [-0.37231413],\n",
      "       [ 0.00566084],\n",
      "       [-0.19112347],\n",
      "       [ 0.5183276 ],\n",
      "       [-0.0426972 ],\n",
      "       [-0.3946634 ],\n",
      "       [-0.46609583],\n",
      "       [-0.45824298],\n",
      "       [-0.17417352],\n",
      "       [-0.30983964],\n",
      "       [-0.11636458],\n",
      "       [ 0.24301603],\n",
      "       [-0.08277405],\n",
      "       [-0.1911087 ]], dtype=float32)> <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([-1.6270809], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "print(w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=6436, shape=(114, 1), dtype=float32, numpy=\n",
       "array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 뽑아낸 w, b값으로 예측하기\n",
    "predict = tf.sigmoid(tf.matmul(test_scaled, w) + b)\n",
    "predict01 = tf.cast(predict > 0.5, dtype=tf.float32)\n",
    "predict01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=6441, shape=(), dtype=float32, numpy=0.7894737>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측값과 실제값이 같은지 확인후 정확도 뽑아내기\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predict01, y_test), dtype='float32'))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': 'breast_cancer.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = datasets.load_breast_cancer()\n",
    "cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30) float64 (569,) int32\n"
     ]
    }
   ],
   "source": [
    "X = cancer.data\n",
    "y = cancer.target\n",
    "print(X.shape, X.dtype, y.shape, y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30) float32 (569, 1) float32\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X, dtype='float32')\n",
    "y = np.array(y, dtype='float32')\n",
    "y = y.reshape(-1,1)\n",
    "print(X.shape, X.dtype, y.shape, y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (114, 30) (455, 1) (114, 1)\n"
     ]
    }
   ],
   "source": [
    "#데이터 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준화\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "train_scaled = ss.transform(X_train)\n",
    "test_scaled = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=30, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientDecent를 이용해 w와 b를 찾는 방법 설정\n",
    "# loss='binary_crossentropy' :  -1 / 데이터수 * (y * np.log(hypothesis) + (1 - y) * (np.log(1 - hypothesis))) 합이 최소가 되는 w와 b를 찾음\n",
    "\n",
    "# optimizer = Adam(learning_rate=0.001) : learning rate를 0.001로 설정\n",
    "# metrics=['acc'] : 정확도를 출력\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\envs\\tensorflow1_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "455/455 [==============================] - 0s 959us/sample - loss: 0.9275 - acc: 0.3824\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s 35us/sample - loss: 0.8236 - acc: 0.4791\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s 28us/sample - loss: 0.7370 - acc: 0.5758\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s 37us/sample - loss: 0.6634 - acc: 0.6659\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s 37us/sample - loss: 0.6028 - acc: 0.7275\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s 38us/sample - loss: 0.5543 - acc: 0.7670\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s 36us/sample - loss: 0.5122 - acc: 0.8000\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s 36us/sample - loss: 0.4761 - acc: 0.8242\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s 35us/sample - loss: 0.4455 - acc: 0.8374\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s 35us/sample - loss: 0.4184 - acc: 0.8462\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s 35us/sample - loss: 0.3942 - acc: 0.8659\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s 36us/sample - loss: 0.3732 - acc: 0.8813\n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s 35us/sample - loss: 0.3545 - acc: 0.8901\n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s 39us/sample - loss: 0.3375 - acc: 0.8967\n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s 32us/sample - loss: 0.3222 - acc: 0.9011\n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s 31us/sample - loss: 0.3079 - acc: 0.9055\n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s 33us/sample - loss: 0.2954 - acc: 0.9121\n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s 35us/sample - loss: 0.2835 - acc: 0.9143\n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s 38us/sample - loss: 0.2727 - acc: 0.9209\n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s 36us/sample - loss: 0.2629 - acc: 0.9275\n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s 38us/sample - loss: 0.2538 - acc: 0.9319\n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s 33us/sample - loss: 0.2455 - acc: 0.9363\n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s 31us/sample - loss: 0.2374 - acc: 0.9363\n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s 30us/sample - loss: 0.2301 - acc: 0.9385\n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s 33us/sample - loss: 0.2236 - acc: 0.9429\n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s 33us/sample - loss: 0.2171 - acc: 0.9495\n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s 28us/sample - loss: 0.2114 - acc: 0.9538\n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s 24us/sample - loss: 0.2058 - acc: 0.9538\n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s 68us/sample - loss: 0.2006 - acc: 0.9560\n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s 32us/sample - loss: 0.1960 - acc: 0.9560\n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s 35us/sample - loss: 0.1916 - acc: 0.9604\n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s 68us/sample - loss: 0.1874 - acc: 0.9604\n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s 33us/sample - loss: 0.1836 - acc: 0.9604\n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s 61us/sample - loss: 0.1798 - acc: 0.9626\n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s 34us/sample - loss: 0.1763 - acc: 0.9626\n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s 28us/sample - loss: 0.1729 - acc: 0.9626\n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s 31us/sample - loss: 0.1698 - acc: 0.9648\n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s 31us/sample - loss: 0.1667 - acc: 0.9648\n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s 31us/sample - loss: 0.1639 - acc: 0.9648\n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s 31us/sample - loss: 0.1612 - acc: 0.9670\n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s 31us/sample - loss: 0.1585 - acc: 0.9692\n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s 55us/sample - loss: 0.1560 - acc: 0.9692\n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s 32us/sample - loss: 0.1537 - acc: 0.9692\n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s 33us/sample - loss: 0.1513 - acc: 0.9692\n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s 62us/sample - loss: 0.1492 - acc: 0.9692\n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s 57us/sample - loss: 0.1470 - acc: 0.9692\n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s 26us/sample - loss: 0.1452 - acc: 0.9692\n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s 28us/sample - loss: 0.1431 - acc: 0.9692\n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s 37us/sample - loss: 0.1413 - acc: 0.9692\n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s 34us/sample - loss: 0.1395 - acc: 0.9692\n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s 29us/sample - loss: 0.1377 - acc: 0.9692\n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s 34us/sample - loss: 0.1360 - acc: 0.9692\n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s 32us/sample - loss: 0.1345 - acc: 0.9714\n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s 34us/sample - loss: 0.1330 - acc: 0.9714\n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s 26us/sample - loss: 0.1314 - acc: 0.9714\n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s 31us/sample - loss: 0.1300 - acc: 0.9714\n",
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s 30us/sample - loss: 0.1286 - acc: 0.9714\n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s 26us/sample - loss: 0.1272 - acc: 0.9714\n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s 65us/sample - loss: 0.1260 - acc: 0.9714\n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s 30us/sample - loss: 0.1247 - acc: 0.9714\n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s 32us/sample - loss: 0.1235 - acc: 0.9714\n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s 32us/sample - loss: 0.1223 - acc: 0.9714\n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s 28us/sample - loss: 0.1212 - acc: 0.9714\n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s 26us/sample - loss: 0.1200 - acc: 0.9714\n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s 60us/sample - loss: 0.1190 - acc: 0.9714\n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s 31us/sample - loss: 0.1180 - acc: 0.9714\n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s 31us/sample - loss: 0.1169 - acc: 0.9714\n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s 31us/sample - loss: 0.1159 - acc: 0.9736\n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s 28us/sample - loss: 0.1150 - acc: 0.9736\n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s 26us/sample - loss: 0.1141 - acc: 0.9736\n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s 32us/sample - loss: 0.1132 - acc: 0.9736\n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s 33us/sample - loss: 0.1123 - acc: 0.9736\n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s 34us/sample - loss: 0.1114 - acc: 0.9736\n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s 32us/sample - loss: 0.1106 - acc: 0.9736\n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s 28us/sample - loss: 0.1097 - acc: 0.9736\n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s 33us/sample - loss: 0.1089 - acc: 0.9736\n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s 33us/sample - loss: 0.1081 - acc: 0.9758\n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s 60us/sample - loss: 0.1073 - acc: 0.9758\n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s 34us/sample - loss: 0.1065 - acc: 0.9758\n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s 34us/sample - loss: 0.1058 - acc: 0.9758\n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s 36us/sample - loss: 0.1051 - acc: 0.9780\n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s 35us/sample - loss: 0.1044 - acc: 0.9780\n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s 31us/sample - loss: 0.1036 - acc: 0.9780\n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s 34us/sample - loss: 0.1029 - acc: 0.9780\n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s 29us/sample - loss: 0.1023 - acc: 0.9780\n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s 32us/sample - loss: 0.1017 - acc: 0.9780\n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s 33us/sample - loss: 0.1011 - acc: 0.9780\n",
      "Epoch 88/100\n",
      "455/455 [==============================] - 0s 52us/sample - loss: 0.1005 - acc: 0.9802\n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s 38us/sample - loss: 0.0999 - acc: 0.9802\n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s 31us/sample - loss: 0.0993 - acc: 0.9802\n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s 33us/sample - loss: 0.0987 - acc: 0.9824\n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s 100us/sample - loss: 0.0982 - acc: 0.9824\n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s 33us/sample - loss: 0.0976 - acc: 0.9824\n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s 32us/sample - loss: 0.0970 - acc: 0.9824\n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s 31us/sample - loss: 0.0966 - acc: 0.9824\n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s 53us/sample - loss: 0.0961 - acc: 0.9824\n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s 32us/sample - loss: 0.0956 - acc: 0.9824\n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s 33us/sample - loss: 0.0950 - acc: 0.9824\n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s 32us/sample - loss: 0.0945 - acc: 0.9824\n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s 61us/sample - loss: 0.0941 - acc: 0.9824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c254dbff08>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력 값을 X, 출력값을 y로 해서 100번 반복해서 w와 b 계산\n",
    "model.fit(train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.1899025e-01],\n",
       "       [1.4279085e-01],\n",
       "       [7.5322247e-01],\n",
       "       [7.9278827e-01],\n",
       "       [9.9085855e-01],\n",
       "       [2.8468317e-01],\n",
       "       [9.8205078e-01],\n",
       "       [9.8985648e-01],\n",
       "       [6.4671040e-06],\n",
       "       [1.7881393e-07],\n",
       "       [8.7924778e-01],\n",
       "       [1.6507506e-04],\n",
       "       [6.7910552e-04],\n",
       "       [9.8338723e-04],\n",
       "       [1.5473932e-01],\n",
       "       [1.4146087e-01],\n",
       "       [9.9091017e-01],\n",
       "       [6.4255089e-02],\n",
       "       [9.9693441e-01],\n",
       "       [4.7683716e-07],\n",
       "       [9.5932305e-01],\n",
       "       [9.9962842e-01],\n",
       "       [9.8110521e-01],\n",
       "       [8.1199759e-01],\n",
       "       [9.9513018e-01],\n",
       "       [8.2863927e-01],\n",
       "       [1.0895580e-02],\n",
       "       [8.1968141e-01],\n",
       "       [9.5605135e-01],\n",
       "       [9.8183274e-01],\n",
       "       [9.8908919e-01],\n",
       "       [7.1183741e-03],\n",
       "       [9.9071956e-01],\n",
       "       [9.4161987e-01],\n",
       "       [9.6354294e-01],\n",
       "       [9.8379064e-01],\n",
       "       [9.5306069e-01],\n",
       "       [1.4552474e-03],\n",
       "       [9.9404305e-01],\n",
       "       [4.8241913e-03],\n",
       "       [6.0177594e-02],\n",
       "       [3.6656857e-06],\n",
       "       [9.9339938e-01],\n",
       "       [9.9987698e-01],\n",
       "       [9.1753101e-01],\n",
       "       [9.9576414e-01],\n",
       "       [9.9516869e-01],\n",
       "       [9.4644761e-01],\n",
       "       [9.9881220e-01],\n",
       "       [1.3258898e-01],\n",
       "       [3.0022085e-01],\n",
       "       [7.6264137e-01],\n",
       "       [2.0909309e-04],\n",
       "       [1.7757416e-03],\n",
       "       [3.7178397e-04],\n",
       "       [2.5677681e-04],\n",
       "       [9.9401236e-01],\n",
       "       [9.9291968e-01],\n",
       "       [7.7184045e-01],\n",
       "       [9.9918103e-01],\n",
       "       [9.9943805e-01],\n",
       "       [9.6630144e-01],\n",
       "       [9.2524993e-01],\n",
       "       [9.9945891e-01],\n",
       "       [1.9917190e-02],\n",
       "       [9.9960196e-01],\n",
       "       [3.3637881e-04],\n",
       "       [2.1689534e-03],\n",
       "       [1.1874616e-02],\n",
       "       [8.9120829e-01],\n",
       "       [9.7810590e-01],\n",
       "       [9.8255253e-01],\n",
       "       [9.9785012e-01],\n",
       "       [1.3719976e-02],\n",
       "       [9.7577786e-01],\n",
       "       [3.4751385e-01],\n",
       "       [8.2214928e-01],\n",
       "       [1.0132790e-06],\n",
       "       [9.4830739e-01],\n",
       "       [4.6699643e-03],\n",
       "       [9.9797308e-01],\n",
       "       [6.6667795e-04],\n",
       "       [9.9864757e-01],\n",
       "       [9.7907007e-01],\n",
       "       [9.7209293e-01],\n",
       "       [7.9350805e-01],\n",
       "       [9.1716444e-01],\n",
       "       [8.6298358e-01],\n",
       "       [9.0722883e-01],\n",
       "       [1.3298625e-01],\n",
       "       [5.3360730e-01],\n",
       "       [9.7537148e-01],\n",
       "       [9.4348103e-01],\n",
       "       [9.3937266e-01],\n",
       "       [8.1986934e-01],\n",
       "       [9.9988067e-01],\n",
       "       [9.7928673e-01],\n",
       "       [9.9894744e-01],\n",
       "       [3.3274204e-01],\n",
       "       [9.6245515e-01],\n",
       "       [9.9618495e-01],\n",
       "       [6.1035156e-05],\n",
       "       [2.2178173e-02],\n",
       "       [9.8533058e-01],\n",
       "       [5.5254191e-02],\n",
       "       [3.8963556e-04],\n",
       "       [9.9832857e-01],\n",
       "       [9.8876464e-01],\n",
       "       [7.2209275e-01],\n",
       "       [2.4184585e-04],\n",
       "       [9.9720836e-01],\n",
       "       [9.9790651e-01],\n",
       "       [9.9059826e-01],\n",
       "       [2.5503719e-02]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_scaled)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict01 = np.where(pred > 0.5, 1, 0)\n",
    "predict01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict02 = predict01.flatten()\n",
    "predict02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict03 = (predict02 == y_test)\n",
    "predict03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predict03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7008.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(tf.cast(predict03, dtype='float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.sum(predict03) / len(predict03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9824561403508771"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow1_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3a336bbbac7a5316600585707c60468fe6500cf7c2d174bf746727352f6e866"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
