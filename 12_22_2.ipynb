{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': 'breast_cancer.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datasets.load_breast_cancer()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30) float64 (569,) int32\n"
     ]
    }
   ],
   "source": [
    "X = data.data\n",
    "y = data.target\n",
    "print(X.shape, X.dtype, y.shape, y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30) float32 (569,) float32\n"
     ]
    }
   ],
   "source": [
    "# 타입 및 형태 변환.\n",
    "X = np.array(X, dtype='float32')\n",
    "y = np.array(y, dtype='float32')\n",
    "print(X.shape, X.dtype, y.shape, y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.reshape(-1,1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X,y 8:2로 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.141e+01, 1.082e+01, 7.334e+01, ..., 8.958e-02, 3.016e-01,\n",
       "        8.523e-02],\n",
       "       [1.426e+01, 1.965e+01, 9.783e+01, ..., 1.505e-01, 2.398e-01,\n",
       "        1.082e-01],\n",
       "       [1.311e+01, 2.254e+01, 8.702e+01, ..., 1.126e-01, 4.128e-01,\n",
       "        1.076e-01],\n",
       "       ...,\n",
       "       [1.575e+01, 2.025e+01, 1.026e+02, ..., 1.479e-01, 3.993e-01,\n",
       "        1.064e-01],\n",
       "       [1.343e+01, 1.963e+01, 8.584e+01, ..., 1.160e-01, 2.884e-01,\n",
       "        7.371e-02],\n",
       "       [1.338e+01, 3.072e+01, 8.634e+01, ..., 7.763e-02, 2.196e-01,\n",
       "        7.675e-02]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (114, 30) (455, 1) (114, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.141e+01, 1.082e+01, 7.334e+01, ..., 8.958e-02, 3.016e-01,\n",
       "        8.523e-02],\n",
       "       [1.426e+01, 1.965e+01, 9.783e+01, ..., 1.505e-01, 2.398e-01,\n",
       "        1.082e-01],\n",
       "       [1.311e+01, 2.254e+01, 8.702e+01, ..., 1.126e-01, 4.128e-01,\n",
       "        1.076e-01],\n",
       "       ...,\n",
       "       [1.575e+01, 2.025e+01, 1.026e+02, ..., 1.479e-01, 3.993e-01,\n",
       "        1.064e-01],\n",
       "       [1.343e+01, 1.963e+01, 8.584e+01, ..., 1.160e-01, 2.884e-01,\n",
       "        7.371e-02],\n",
       "       [1.338e+01, 3.072e+01, 8.634e+01, ..., 7.763e-02, 2.196e-01,\n",
       "        7.675e-02]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습하기 전에 데이터 표준화\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "train_scaled = ss.transform(X_train)\n",
    "test_scaled = ss.transform(X_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid 함수 정의\n",
    "\n",
    "def sigmoid(h):\n",
    "    return 1 / (1 + np.exp(-h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w, b 초기화 시키는 객체 생성\n",
    "initializer = tf.contrib.layers.xavier_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w 및 b 생성\n",
    "w = tf.Variable(initializer([30,1]))\n",
    "b = tf.Variable(initializer([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=32, shape=(455, 1), dtype=float32, numpy=\n",
       "array([[0.91964334],\n",
       "       [0.10414162],\n",
       "       [0.82337296],\n",
       "       [0.6369169 ],\n",
       "       [0.9011744 ],\n",
       "       [0.58958113],\n",
       "       [0.31974596],\n",
       "       [0.7374135 ],\n",
       "       [0.761508  ],\n",
       "       [0.7893415 ],\n",
       "       [0.8394147 ],\n",
       "       [0.23063067],\n",
       "       [0.90862584],\n",
       "       [0.5002521 ],\n",
       "       [0.7084362 ],\n",
       "       [0.59987426],\n",
       "       [0.77379405],\n",
       "       [0.78466624],\n",
       "       [0.42972746],\n",
       "       [0.29977807],\n",
       "       [0.50970685],\n",
       "       [0.1058625 ],\n",
       "       [0.54150426],\n",
       "       [0.54590946],\n",
       "       [0.04952678],\n",
       "       [0.81065416],\n",
       "       [0.5935625 ],\n",
       "       [0.6699424 ],\n",
       "       [0.7118197 ],\n",
       "       [0.6919981 ],\n",
       "       [0.7011708 ],\n",
       "       [0.68469393],\n",
       "       [0.8786967 ],\n",
       "       [0.7491182 ],\n",
       "       [0.81774724],\n",
       "       [0.73419726],\n",
       "       [0.9521642 ],\n",
       "       [0.93956274],\n",
       "       [0.60427177],\n",
       "       [0.51387197],\n",
       "       [0.3981533 ],\n",
       "       [0.7851532 ],\n",
       "       [0.22972086],\n",
       "       [0.5912448 ],\n",
       "       [0.83662564],\n",
       "       [0.49295813],\n",
       "       [0.80643076],\n",
       "       [0.83587587],\n",
       "       [0.6785614 ],\n",
       "       [0.89057046],\n",
       "       [0.4702616 ],\n",
       "       [0.75742555],\n",
       "       [0.6776132 ],\n",
       "       [0.9100393 ],\n",
       "       [0.8525442 ],\n",
       "       [0.7477341 ],\n",
       "       [0.7357732 ],\n",
       "       [0.8446451 ],\n",
       "       [0.6771114 ],\n",
       "       [0.9176109 ],\n",
       "       [0.73280203],\n",
       "       [0.83080196],\n",
       "       [0.77081555],\n",
       "       [0.46841937],\n",
       "       [0.6739043 ],\n",
       "       [0.47074598],\n",
       "       [0.8379892 ],\n",
       "       [0.8033695 ],\n",
       "       [0.2717436 ],\n",
       "       [0.2888844 ],\n",
       "       [0.6901342 ],\n",
       "       [0.32127434],\n",
       "       [0.6127488 ],\n",
       "       [0.73817813],\n",
       "       [0.16741288],\n",
       "       [0.57333964],\n",
       "       [0.79334414],\n",
       "       [0.54303473],\n",
       "       [0.80673087],\n",
       "       [0.48597166],\n",
       "       [0.7680496 ],\n",
       "       [0.7777556 ],\n",
       "       [0.780125  ],\n",
       "       [0.62075126],\n",
       "       [0.48781282],\n",
       "       [0.46805358],\n",
       "       [0.86258197],\n",
       "       [0.58598614],\n",
       "       [0.7706075 ],\n",
       "       [0.50129443],\n",
       "       [0.27749145],\n",
       "       [0.95573926],\n",
       "       [0.23726895],\n",
       "       [0.8063197 ],\n",
       "       [0.8705639 ],\n",
       "       [0.44410732],\n",
       "       [0.33246356],\n",
       "       [0.6909564 ],\n",
       "       [0.4718687 ],\n",
       "       [0.7760669 ],\n",
       "       [0.6227135 ],\n",
       "       [0.8501957 ],\n",
       "       [0.43178773],\n",
       "       [0.5944256 ],\n",
       "       [0.72859097],\n",
       "       [0.03326344],\n",
       "       [0.8160946 ],\n",
       "       [0.8144257 ],\n",
       "       [0.85412216],\n",
       "       [0.8060149 ],\n",
       "       [0.8873422 ],\n",
       "       [0.71854264],\n",
       "       [0.7954705 ],\n",
       "       [0.8399676 ],\n",
       "       [0.74898404],\n",
       "       [0.74274015],\n",
       "       [0.94333476],\n",
       "       [0.9225663 ],\n",
       "       [0.67075276],\n",
       "       [0.43498972],\n",
       "       [0.5600836 ],\n",
       "       [0.8347436 ],\n",
       "       [0.39879578],\n",
       "       [0.7829678 ],\n",
       "       [0.9610874 ],\n",
       "       [0.23640859],\n",
       "       [0.5121278 ],\n",
       "       [0.8432057 ],\n",
       "       [0.5025695 ],\n",
       "       [0.86757535],\n",
       "       [0.7692851 ],\n",
       "       [0.27995247],\n",
       "       [0.49364924],\n",
       "       [0.62564105],\n",
       "       [0.46063253],\n",
       "       [0.12315854],\n",
       "       [0.67056084],\n",
       "       [0.28360817],\n",
       "       [0.34655145],\n",
       "       [0.7101792 ],\n",
       "       [0.8628225 ],\n",
       "       [0.6751663 ],\n",
       "       [0.38595694],\n",
       "       [0.4494533 ],\n",
       "       [0.7165037 ],\n",
       "       [0.8216464 ],\n",
       "       [0.5963347 ],\n",
       "       [0.84557223],\n",
       "       [0.61981994],\n",
       "       [0.81154895],\n",
       "       [0.8217338 ],\n",
       "       [0.80711037],\n",
       "       [0.00665915],\n",
       "       [0.386789  ],\n",
       "       [0.20140979],\n",
       "       [0.94270486],\n",
       "       [0.7900712 ],\n",
       "       [0.96382886],\n",
       "       [0.62613434],\n",
       "       [0.8724395 ],\n",
       "       [0.35822952],\n",
       "       [0.6359754 ],\n",
       "       [0.56239927],\n",
       "       [0.78357726],\n",
       "       [0.6721591 ],\n",
       "       [0.84397894],\n",
       "       [0.66918695],\n",
       "       [0.87380683],\n",
       "       [0.51343304],\n",
       "       [0.62750065],\n",
       "       [0.52800894],\n",
       "       [0.77551866],\n",
       "       [0.69069916],\n",
       "       [0.05592087],\n",
       "       [0.28771806],\n",
       "       [0.90763485],\n",
       "       [0.68087864],\n",
       "       [0.82291895],\n",
       "       [0.32865894],\n",
       "       [0.86846197],\n",
       "       [0.6845824 ],\n",
       "       [0.21457517],\n",
       "       [0.6559861 ],\n",
       "       [0.24379197],\n",
       "       [0.6163938 ],\n",
       "       [0.48078212],\n",
       "       [0.18859053],\n",
       "       [0.3544469 ],\n",
       "       [0.00551152],\n",
       "       [0.8960949 ],\n",
       "       [0.73667103],\n",
       "       [0.6347125 ],\n",
       "       [0.24748808],\n",
       "       [0.5877574 ],\n",
       "       [0.89562905],\n",
       "       [0.6246434 ],\n",
       "       [0.5119132 ],\n",
       "       [0.33826768],\n",
       "       [0.28987232],\n",
       "       [0.30717224],\n",
       "       [0.7171639 ],\n",
       "       [0.7512531 ],\n",
       "       [0.6493617 ],\n",
       "       [0.39718127],\n",
       "       [0.8011998 ],\n",
       "       [0.88894415],\n",
       "       [0.06420499],\n",
       "       [0.8159945 ],\n",
       "       [0.3198193 ],\n",
       "       [0.6162081 ],\n",
       "       [0.6745721 ],\n",
       "       [0.7567823 ],\n",
       "       [0.24702185],\n",
       "       [0.79851305],\n",
       "       [0.6948068 ],\n",
       "       [0.6420141 ],\n",
       "       [0.66355073],\n",
       "       [0.5498923 ],\n",
       "       [0.7900312 ],\n",
       "       [0.66858685],\n",
       "       [0.2756608 ],\n",
       "       [0.25740212],\n",
       "       [0.03807029],\n",
       "       [0.7840134 ],\n",
       "       [0.8548329 ],\n",
       "       [0.26955009],\n",
       "       [0.74823797],\n",
       "       [0.60625494],\n",
       "       [0.8227498 ],\n",
       "       [0.6131037 ],\n",
       "       [0.72396576],\n",
       "       [0.6799707 ],\n",
       "       [0.5835278 ],\n",
       "       [0.65266883],\n",
       "       [0.7032392 ],\n",
       "       [0.841099  ],\n",
       "       [0.11345646],\n",
       "       [0.6841117 ],\n",
       "       [0.8131638 ],\n",
       "       [0.91346675],\n",
       "       [0.7980292 ],\n",
       "       [0.56958336],\n",
       "       [0.7192335 ],\n",
       "       [0.5172449 ],\n",
       "       [0.83019054],\n",
       "       [0.8726707 ],\n",
       "       [0.26447278],\n",
       "       [0.7225589 ],\n",
       "       [0.60283303],\n",
       "       [0.8374972 ],\n",
       "       [0.28812265],\n",
       "       [0.6580298 ],\n",
       "       [0.6327062 ],\n",
       "       [0.9136938 ],\n",
       "       [0.6916118 ],\n",
       "       [0.4038663 ],\n",
       "       [0.7799274 ],\n",
       "       [0.08765578],\n",
       "       [0.9293498 ],\n",
       "       [0.88862866],\n",
       "       [0.86962724],\n",
       "       [0.4402704 ],\n",
       "       [0.7998526 ],\n",
       "       [0.5894146 ],\n",
       "       [0.7989563 ],\n",
       "       [0.6245818 ],\n",
       "       [0.7317636 ],\n",
       "       [0.7909128 ],\n",
       "       [0.7608834 ],\n",
       "       [0.20245042],\n",
       "       [0.3051511 ],\n",
       "       [0.7958428 ],\n",
       "       [0.67690927],\n",
       "       [0.0368458 ],\n",
       "       [0.8919883 ],\n",
       "       [0.24839753],\n",
       "       [0.24852219],\n",
       "       [0.46215528],\n",
       "       [0.40938947],\n",
       "       [0.4336761 ],\n",
       "       [0.37797597],\n",
       "       [0.09901243],\n",
       "       [0.13649818],\n",
       "       [0.45212808],\n",
       "       [0.6096406 ],\n",
       "       [0.8771541 ],\n",
       "       [0.75535727],\n",
       "       [0.7464912 ],\n",
       "       [0.33216596],\n",
       "       [0.43838012],\n",
       "       [0.4815856 ],\n",
       "       [0.7486931 ],\n",
       "       [0.7938572 ],\n",
       "       [0.8333343 ],\n",
       "       [0.40888432],\n",
       "       [0.8144845 ],\n",
       "       [0.66052914],\n",
       "       [0.77104247],\n",
       "       [0.69783914],\n",
       "       [0.24845171],\n",
       "       [0.86661315],\n",
       "       [0.19282761],\n",
       "       [0.51914316],\n",
       "       [0.81929046],\n",
       "       [0.70531416],\n",
       "       [0.91968054],\n",
       "       [0.8383813 ],\n",
       "       [0.7781672 ],\n",
       "       [0.6786611 ],\n",
       "       [0.7328768 ],\n",
       "       [0.64603597],\n",
       "       [0.7609743 ],\n",
       "       [0.8164966 ],\n",
       "       [0.13930464],\n",
       "       [0.88105935],\n",
       "       [0.71165144],\n",
       "       [0.34923893],\n",
       "       [0.47740987],\n",
       "       [0.70599693],\n",
       "       [0.70543635],\n",
       "       [0.41900173],\n",
       "       [0.65749824],\n",
       "       [0.33165854],\n",
       "       [0.8475547 ],\n",
       "       [0.49155933],\n",
       "       [0.76799965],\n",
       "       [0.7978728 ],\n",
       "       [0.81734097],\n",
       "       [0.81207746],\n",
       "       [0.7834368 ],\n",
       "       [0.4630459 ],\n",
       "       [0.736508  ],\n",
       "       [0.52280635],\n",
       "       [0.43412256],\n",
       "       [0.7934183 ],\n",
       "       [0.8245737 ],\n",
       "       [0.670508  ],\n",
       "       [0.9265027 ],\n",
       "       [0.14285126],\n",
       "       [0.8702968 ],\n",
       "       [0.73141813],\n",
       "       [0.86815816],\n",
       "       [0.62881225],\n",
       "       [0.8317388 ],\n",
       "       [0.8906299 ],\n",
       "       [0.6070564 ],\n",
       "       [0.92757905],\n",
       "       [0.72029835],\n",
       "       [0.48922035],\n",
       "       [0.6043419 ],\n",
       "       [0.80262136],\n",
       "       [0.91490114],\n",
       "       [0.2497809 ],\n",
       "       [0.44429722],\n",
       "       [0.8394784 ],\n",
       "       [0.96867865],\n",
       "       [0.3686996 ],\n",
       "       [0.7960659 ],\n",
       "       [0.89262766],\n",
       "       [0.5754693 ],\n",
       "       [0.80177075],\n",
       "       [0.5024347 ],\n",
       "       [0.86069393],\n",
       "       [0.06927335],\n",
       "       [0.57914233],\n",
       "       [0.31590465],\n",
       "       [0.7893663 ],\n",
       "       [0.7897359 ],\n",
       "       [0.90295166],\n",
       "       [0.8860569 ],\n",
       "       [0.6842238 ],\n",
       "       [0.87856895],\n",
       "       [0.7170436 ],\n",
       "       [0.53772557],\n",
       "       [0.414047  ],\n",
       "       [0.67196107],\n",
       "       [0.41874546],\n",
       "       [0.8657038 ],\n",
       "       [0.50431913],\n",
       "       [0.7662058 ],\n",
       "       [0.7128885 ],\n",
       "       [0.8841112 ],\n",
       "       [0.8868485 ],\n",
       "       [0.41836458],\n",
       "       [0.56049716],\n",
       "       [0.5399112 ],\n",
       "       [0.8369199 ],\n",
       "       [0.7511245 ],\n",
       "       [0.8596337 ],\n",
       "       [0.71126795],\n",
       "       [0.51910824],\n",
       "       [0.9336488 ],\n",
       "       [0.28259748],\n",
       "       [0.36222214],\n",
       "       [0.872346  ],\n",
       "       [0.85995924],\n",
       "       [0.4259834 ],\n",
       "       [0.4846253 ],\n",
       "       [0.82324016],\n",
       "       [0.7438806 ],\n",
       "       [0.33369556],\n",
       "       [0.21793911],\n",
       "       [0.8038853 ],\n",
       "       [0.9044749 ],\n",
       "       [0.7321616 ],\n",
       "       [0.03736895],\n",
       "       [0.8320798 ],\n",
       "       [0.82310176],\n",
       "       [0.7342686 ],\n",
       "       [0.8199847 ],\n",
       "       [0.8370274 ],\n",
       "       [0.7621738 ],\n",
       "       [0.8370409 ],\n",
       "       [0.13706058],\n",
       "       [0.6152695 ],\n",
       "       [0.6431061 ],\n",
       "       [0.53779936],\n",
       "       [0.9183425 ],\n",
       "       [0.50368184],\n",
       "       [0.09225246],\n",
       "       [0.8565669 ],\n",
       "       [0.7804636 ],\n",
       "       [0.7490558 ],\n",
       "       [0.6357339 ],\n",
       "       [0.8296074 ],\n",
       "       [0.79482317],\n",
       "       [0.7575265 ],\n",
       "       [0.37221912],\n",
       "       [0.18113598],\n",
       "       [0.8820143 ],\n",
       "       [0.68376297],\n",
       "       [0.7414916 ],\n",
       "       [0.92564577],\n",
       "       [0.75297785],\n",
       "       [0.77391905],\n",
       "       [0.436142  ],\n",
       "       [0.8392111 ],\n",
       "       [0.8016386 ],\n",
       "       [0.45166945],\n",
       "       [0.20344609],\n",
       "       [0.86940897],\n",
       "       [0.5287171 ],\n",
       "       [0.09533629],\n",
       "       [0.6382519 ],\n",
       "       [0.43157792],\n",
       "       [0.2693051 ],\n",
       "       [0.6027768 ],\n",
       "       [0.8714665 ],\n",
       "       [0.6264957 ],\n",
       "       [0.45014283],\n",
       "       [0.15185559],\n",
       "       [0.7875502 ],\n",
       "       [0.8731982 ],\n",
       "       [0.8266603 ],\n",
       "       [0.6201054 ]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측값 계산하기\n",
    "hypothesis = tf.sigmoid(tf.matmul(train_scaled, w) + b)\n",
    "hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_2040\\3535778523.py:2: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# optimizer 생성\n",
    "optimizer = tf.train.AdamOptimizer(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "step : 0, cost : 0.559338390827179, w : [[-0.3542775 ]\n",
      " [-0.28306985]\n",
      " [ 0.07462971]\n",
      " [-0.0380059 ]\n",
      " [-0.43789795]\n",
      " [ 0.28538746]\n",
      " [ 0.14387242]\n",
      " [-0.2732712 ]\n",
      " [ 0.11815482]\n",
      " [-0.21943294]\n",
      " [ 0.19457309]\n",
      " [-0.16639592]\n",
      " [ 0.33983284]\n",
      " [-0.22675768]\n",
      " [-0.05354773]\n",
      " [-0.21158414]\n",
      " [-0.12790638]\n",
      " [-0.42345816]\n",
      " [-0.2426768 ]\n",
      " [-0.02246519]\n",
      " [ 0.1747111 ]\n",
      " [ 0.23637246]\n",
      " [-0.28005403]\n",
      " [ 0.02371087]\n",
      " [ 0.37759572]\n",
      " [-0.10922863]\n",
      " [-0.41063267]\n",
      " [-0.24842526]\n",
      " [ 0.40275478]\n",
      " [ 0.3862669 ]], b : [0.6058489]\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "step : 10, cost : 0.5171224474906921, w : [[-0.3642323 ]\n",
      " [-0.29303637]\n",
      " [ 0.06467553]\n",
      " [-0.04795929]\n",
      " [-0.44785172]\n",
      " [ 0.27544197]\n",
      " [ 0.13392621]\n",
      " [-0.2832231 ]\n",
      " [ 0.10819527]\n",
      " [-0.2094403 ]\n",
      " [ 0.18462557]\n",
      " [-0.15642981]\n",
      " [ 0.32988778]\n",
      " [-0.23670542]\n",
      " [-0.04358222]\n",
      " [-0.2014197 ]\n",
      " [-0.11783543]\n",
      " [-0.4262537 ]\n",
      " [-0.23270667]\n",
      " [-0.01246508]\n",
      " [ 0.1647532 ]\n",
      " [ 0.22640023]\n",
      " [-0.29001123]\n",
      " [ 0.01375479]\n",
      " [ 0.36762473]\n",
      " [-0.11918761]\n",
      " [-0.42058763]\n",
      " [-0.25838226]\n",
      " [ 0.39278215]\n",
      " [ 0.3763024 ]], b : [0.6158488]\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "step : 20, cost : 0.47902631759643555, w : [[-0.37399042]\n",
      " [-0.30285722]\n",
      " [ 0.05492033]\n",
      " [-0.05771054]\n",
      " [-0.45760852]\n",
      " [ 0.2657288 ]\n",
      " [ 0.12420999]\n",
      " [-0.29296815]\n",
      " [ 0.09841014]\n",
      " [-0.19950397]\n",
      " [ 0.17489883]\n",
      " [-0.14662416]\n",
      " [ 0.32017243]\n",
      " [-0.2464314 ]\n",
      " [-0.03378546]\n",
      " [-0.19077043]\n",
      " [-0.10753557]\n",
      " [-0.41672906]\n",
      " [-0.22288431]\n",
      " [-0.00248853]\n",
      " [ 0.15497912]\n",
      " [ 0.21655102]\n",
      " [-0.29978192]\n",
      " [ 0.00399045]\n",
      " [ 0.35778087]\n",
      " [-0.12897012]\n",
      " [-0.43034866]\n",
      " [-0.2681543 ]\n",
      " [ 0.38293162]\n",
      " [ 0.36649066]], b : [0.6258357]\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "step : 30, cost : 0.44501712918281555, w : [[-0.38342446]\n",
      " [-0.31243837]\n",
      " [ 0.04549258]\n",
      " [-0.0671298 ]\n",
      " [-0.46704426]\n",
      " [ 0.25639242]\n",
      " [ 0.11486702]\n",
      " [-0.3023764 ]\n",
      " [ 0.08891303]\n",
      " [-0.18969662]\n",
      " [ 0.16552368]\n",
      " [-0.13710585]\n",
      " [ 0.31082043]\n",
      " [-0.25580135]\n",
      " [-0.02429914]\n",
      " [-0.17965832]\n",
      " [-0.09698469]\n",
      " [-0.40478766]\n",
      " [-0.2133365 ]\n",
      " [ 0.00740943]\n",
      " [ 0.14550965]\n",
      " [ 0.20690885]\n",
      " [-0.3092442 ]\n",
      " [-0.00545658]\n",
      " [ 0.34815055]\n",
      " [-0.13846402]\n",
      " [-0.43979263]\n",
      " [-0.27762344]\n",
      " [ 0.37328956]\n",
      " [ 0.35692915]], b : [0.6357739]\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "step : 40, cost : 0.4148796796798706, w : [[-0.39245963]\n",
      " [-0.32172555]\n",
      " [ 0.03646745]\n",
      " [-0.07614191]\n",
      " [-0.47608325]\n",
      " [ 0.24751647]\n",
      " [ 0.10597903]\n",
      " [-0.31137264]\n",
      " [ 0.07977506]\n",
      " [-0.18007594]\n",
      " [ 0.15656942]\n",
      " [-0.12796499]\n",
      " [ 0.30190122]\n",
      " [-0.26474246]\n",
      " [-0.01522668]\n",
      " [-0.16824593]\n",
      " [-0.08624155]\n",
      " [-0.39193392]\n",
      " [-0.20415802]\n",
      " [ 0.01717259]\n",
      " [ 0.13641675]\n",
      " [ 0.1975256 ]\n",
      " [-0.31832576]\n",
      " [-0.01451182]\n",
      " [ 0.33879003]\n",
      " [-0.14760324]\n",
      " [-0.44884774]\n",
      " [-0.28672034]\n",
      " [ 0.36391264]\n",
      " [ 0.34767666]], b : [0.64561224]\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "step : 50, cost : 0.38825055956840515, w : [[-0.40106797]\n",
      " [-0.33069983]\n",
      " [ 0.02787279]\n",
      " [-0.08471979]\n",
      " [-0.48469272]\n",
      " [ 0.23913056]\n",
      " [ 0.09757307]\n",
      " [-0.3199306 ]\n",
      " [ 0.07102716]\n",
      " [-0.17068033]\n",
      " [ 0.14805345]\n",
      " [-0.1192541 ]\n",
      " [ 0.29343048]\n",
      " [-0.27323407]\n",
      " [-0.00663014]\n",
      " [-0.1567275 ]\n",
      " [-0.07539961]\n",
      " [-0.37871248]\n",
      " [-0.1954089 ]\n",
      " [ 0.02675241]\n",
      " [ 0.12772852]\n",
      " [ 0.1884233 ]\n",
      " [-0.32699853]\n",
      " [-0.02314676]\n",
      " [ 0.32972726]\n",
      " [-0.15636285]\n",
      " [-0.4574881 ]\n",
      " [-0.29541883]\n",
      " [ 0.35482845]\n",
      " [ 0.33875662]], b : [0.65528005]\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "step : 60, cost : 0.3647131621837616, w : [[-0.40925294]\n",
      " [-0.33936584]\n",
      " [ 0.01970474]\n",
      " [-0.09286831]\n",
      " [-0.4928693 ]\n",
      " [ 0.23122808]\n",
      " [ 0.08963951]\n",
      " [-0.3280566 ]\n",
      " [ 0.06267146]\n",
      " [-0.16153087]\n",
      " [ 0.13995968]\n",
      " [-0.11099766]\n",
      " [ 0.28539002]\n",
      " [-0.28128925]\n",
      " [ 0.00146119]\n",
      " [-0.14527656]\n",
      " [-0.0645564 ]\n",
      " [-0.3654509 ]\n",
      " [-0.18712176]\n",
      " [ 0.036111  ]\n",
      " [ 0.11944309]\n",
      " [ 0.17960317]\n",
      " [-0.3352648 ]\n",
      " [-0.03136422]\n",
      " [ 0.32097   ]\n",
      " [-0.16474515]\n",
      " [-0.4657188 ]\n",
      " [-0.30372196]\n",
      " [ 0.3460434 ]\n",
      " [ 0.33016866]], b : [0.6646936]\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "step : 70, cost : 0.34386080503463745, w : [[-0.41703513]\n",
      " [-0.34774083]\n",
      " [ 0.01194234]\n",
      " [-0.10060944]\n",
      " [-0.5006255 ]\n",
      " [ 0.22378339]\n",
      " [ 0.08214889]\n",
      " [-0.33577403]\n",
      " [ 0.05469322]\n",
      " [-0.15263514]\n",
      " [ 0.13225496]\n",
      " [-0.10320221]\n",
      " [ 0.27774477]\n",
      " [-0.2889382 ]\n",
      " [ 0.00903996]\n",
      " [-0.1340282 ]\n",
      " [-0.05379916]\n",
      " [-0.352365  ]\n",
      " [-0.17931089]\n",
      " [ 0.04522038]\n",
      " [ 0.11154212]\n",
      " [ 0.1710546 ]\n",
      " [-0.34314346]\n",
      " [-0.03918425]\n",
      " [ 0.31251407]\n",
      " [-0.17276686]\n",
      " [-0.47356173]\n",
      " [-0.31164858]\n",
      " [ 0.33755115]\n",
      " [ 0.32189968]], b : [0.67376953]\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "step : 80, cost : 0.3253270387649536, w : [[-0.42444217]\n",
      " [-0.35584673]\n",
      " [ 0.00455741]\n",
      " [-0.10797229]\n",
      " [-0.50798076]\n",
      " [ 0.21676332]\n",
      " [ 0.07506315]\n",
      " [-0.34311363]\n",
      " [ 0.04706938]\n",
      " [-0.14399198]\n",
      " [ 0.12490001]\n",
      " [-0.09586414]\n",
      " [ 0.27045432]\n",
      " [-0.29621753]\n",
      " [ 0.01611201]\n",
      " [-0.12308027]\n",
      " [-0.04320218]\n",
      " [-0.3396004 ]\n",
      " [-0.1719791 ]\n",
      " [ 0.0540599 ]\n",
      " [ 0.10400001]\n",
      " [ 0.16276173]\n",
      " [-0.35066056]\n",
      " [-0.04663437]\n",
      " [ 0.30434957]\n",
      " [-0.18045041]\n",
      " [-0.48104605]\n",
      " [-0.31922424]\n",
      " [ 0.32933864]\n",
      " [ 0.3139313 ]], b : [0.68243337]\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "step : 90, cost : 0.30879440903663635, w : [[-0.4315036 ]\n",
      " [-0.36370635]\n",
      " [-0.0024799 ]\n",
      " [-0.11498747]\n",
      " [-0.51495713]\n",
      " [ 0.2101334 ]\n",
      " [ 0.06834191]\n",
      " [-0.35010746]\n",
      " [ 0.03977365]\n",
      " [-0.13559577]\n",
      " [ 0.11785514]\n",
      " [-0.08897447]\n",
      " [ 0.2634786 ]\n",
      " [-0.30316448]\n",
      " [ 0.02269044]\n",
      " [-0.11250123]\n",
      " [-0.03282905]\n",
      " [-0.32725894]\n",
      " [-0.16512218]\n",
      " [ 0.06261338]\n",
      " [ 0.09678922]\n",
      " [ 0.15470724]\n",
      " [-0.35784405]\n",
      " [-0.05374402]\n",
      " [ 0.29646376]\n",
      " [-0.18781924]\n",
      " [-0.48820296]\n",
      " [-0.32647595]\n",
      " [ 0.32139024]\n",
      " [ 0.30624402]], b : [0.6906252]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 반복해서 w와 b를 찾음\n",
    "\n",
    "for step in range(100):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = tf.sigmoid(tf.matmul(train_scaled, w) + b)\n",
    "        cost = -tf.reduce_mean(y_train * tf.log(hypothesis) + (1 - y_train) * tf.log(1 - hypothesis))\n",
    "        grads = tape.gradient(cost, [w,b])\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, [w,b]))\n",
    "\n",
    "    if step % 10 ==0:\n",
    "        print('-'*50)\n",
    "        print(f'step : {step}, cost : {cost.numpy()}, w : {w.numpy()}, b : {b.numpy()}')\n",
    "        print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(30, 1) dtype=float32, numpy=\n",
      "array([[-0.43758687],\n",
      "       [-0.3705871 ],\n",
      "       [-0.00854006],\n",
      "       [-0.12102823],\n",
      "       [-0.52092963],\n",
      "       [ 0.20447308],\n",
      "       [ 0.06257159],\n",
      "       [-0.3561317 ],\n",
      "       [ 0.0334659 ],\n",
      "       [-0.12824439],\n",
      "       [ 0.11174894],\n",
      "       [-0.08314761],\n",
      "       [ 0.25743887],\n",
      "       [-0.30916142],\n",
      "       [ 0.0282028 ],\n",
      "       [-0.10333458],\n",
      "       [-0.02373126],\n",
      "       [-0.31657556],\n",
      "       [-0.15934986],\n",
      "       [ 0.07005533],\n",
      "       [ 0.09056062],\n",
      "       [ 0.14764798],\n",
      "       [-0.36404642],\n",
      "       [-0.05987528],\n",
      "       [ 0.28959385],\n",
      "       [-0.19420046],\n",
      "       [-0.4943896 ],\n",
      "       [-0.33274737],\n",
      "       [ 0.3144491 ],\n",
      "       [ 0.29955   ]], dtype=float32)> <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.6975574], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "print(w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=6442, shape=(114, 1), dtype=float32, numpy=\n",
       "array([[1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 뽑아낸 w, b값으로 예측하기\n",
    "predict = tf.sigmoid(tf.matmul(test_scaled, w) + b)\n",
    "predict01 = tf.cast(predict > 0.5, dtype=tf.float32)\n",
    "predict01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=6447, shape=(), dtype=float32, numpy=0.8684211>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측값과 실제값이 같은지 확인후 정확도 뽑아내기\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predict01, y_test), dtype='float32'))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': 'breast_cancer.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = datasets.load_breast_cancer()\n",
    "cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30) float64 (569,) int32\n"
     ]
    }
   ],
   "source": [
    "X = cancer.data\n",
    "y = cancer.target\n",
    "print(X.shape, X.dtype, y.shape, y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30) float32 (569, 1) float32\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X, dtype='float32')\n",
    "y = np.array(y, dtype='float32')\n",
    "y = y.reshape(-1,1)\n",
    "print(X.shape, X.dtype, y.shape, y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (114, 30) (455, 1) (114, 1)\n"
     ]
    }
   ],
   "source": [
    "#데이터 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준화\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "train_scaled = ss.transform(X_train)\n",
    "test_scaled = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=30, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow1_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3a336bbbac7a5316600585707c60468fe6500cf7c2d174bf746727352f6e866"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
